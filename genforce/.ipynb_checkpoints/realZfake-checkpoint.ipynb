{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import utils.inverter as inv\n",
    "from models.stylegan_generator_idinvert import StyleGANGeneratorIdinvert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings\n",
    "path_images = '/Users/max/Desktop/FFHQ'\n",
    "n_iter = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-12-28 14:01:12,859][INFO] Build network for module `generator` in model `styleganinv_ffhq256`.\n",
      "[2020-12-28 14:01:13,132][INFO] Loading pytorch weights from `models/pretrain/styleganinv_ffhq256_generator.pth`.\n",
      "[2020-12-28 14:01:13,517][INFO] Successfully loaded!\n",
      "[2020-12-28 14:01:13,540][INFO] Current `lod` is 0.0.\n",
      "[2020-12-28 14:01:13,542][INFO] Build network for module `encoder` in model `styleganinv_ffhq256`.\n",
      "[2020-12-28 14:01:14,718][INFO] Loading pytorch weights from `models/pretrain/styleganinv_ffhq256_encoder.pth`.\n",
      "[2020-12-28 14:01:16,815][INFO] Successfully loaded!\n"
     ]
    }
   ],
   "source": [
    "# initialize generator & invertor\n",
    "G = StyleGANGeneratorIdinvert('styleganinv_ffhq256')\n",
    "Inverter = inv.StyleGANInverter(G, 'styleganinv_ffhq256', iteration=n_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image):\n",
    "    image = image[:,:,:3]\n",
    "    image = cv2.resize(image, (256, 256))\n",
    "    image = image.astype(np.float32)\n",
    "    image = image * 2 - 1\n",
    "    return image.astype(np.float32).transpose(2, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss_pix: 0.096, loss_feat: 6908.397, loss_reg: 0.095, loss: 0.632: 100%|██████████| 3/3 [00:25<00:00,  8.37s/it]    \n",
      "loss_pix: 0.047, loss_feat: 4491.565, loss_reg: 0.038, loss: 0.348: 100%|██████████| 3/3 [00:26<00:00,  8.80s/it]\n",
      "loss_pix: 0.147, loss_feat: 11304.095, loss_reg: 0.067, loss: 0.846: 100%|██████████| 3/3 [00:25<00:00,  8.65s/it]\n",
      "loss_pix: 0.063, loss_feat: 6518.699, loss_reg: 0.048, loss: 0.484: 100%|██████████| 3/3 [00:25<00:00,  8.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8976312677065532 min\n",
      "= 0.0316273252831565 h\n"
     ]
    }
   ],
   "source": [
    "# process images in packages of 1000\n",
    "\n",
    "latents = []\n",
    "fakes = []\n",
    "losses = []\n",
    "start = time.time()\n",
    "\n",
    "for i in range(11):\n",
    "    \n",
    "    # read .png files\n",
    "    real_list = []\n",
    "    for j in range(1000):\n",
    "        file = path_images+'/'+str(i*1000).zfill(5)+'/'+str(i*1000+j).zfill(5)+'.png'\n",
    "        real_list.append(preprocess(plt.imread(file)))\n",
    "\n",
    "    real = torch.from_numpy(np.array(real_list))\n",
    "\n",
    "    # create optimized latent code & fake images\n",
    "    for k in range(real.shape[0]):\n",
    "        latent, fake, loss = Inverter.invert_offline(image=real[k].unsqueeze(0))\n",
    "        latents.append(latent.squeeze().detach().numpy())\n",
    "        fakes.append(fake.squeeze().detach().numpy())\n",
    "        losses.append(loss)\n",
    "        \n",
    "latents = np.array(latents)\n",
    "fakes = np.array(fakes)\n",
    "losses = np.array(losses)\n",
    "    \n",
    "print((time.time()-start)/60, 'min')\n",
    "print('=',(time.time()-start)/3600, 'h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "pickle.dump(latents, open( \"lat.p\", \"wb\" ))\n",
    "pickle.dump(fakes, open( \"fak.p\", \"wb\" ))\n",
    "pickle.dump(losses, open( \"los.p\", \"wb\" ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DLP",
   "language": "python",
   "name": "dlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
